import streamlit as st import requests from bs4 import BeautifulSoup from langchain.text_splitter import CharacterTextSplitter import openai from langchain.chat_models import ChatOpenAI from langchain.vectorstores import FAISS from langchain.chains import RetrievalQA from langchain.document_loaders import PyPDFLoader from datetime import datetime import sqlite3 import os import tempfile

ì»¤ìŠ¤í…€ HyperCLOVA X ì„ë² ë”© ë˜í¼ í´ë˜ìŠ¤

def HyperclovaEmbeddings(api_key=None, model="hyperclova-x-embedding", base_url=None): class _Wrapper: def init(self, api_key, model, base_url): self.model = model openai.api_key = api_key or os.getenv("OPENAI_API_KEY") if base_url: openai.api_base = base_url.rstrip("/") def embed_documents(self, texts): response = openai.Embedding.create( model=self.model, input=texts ) return [datum.embedding for datum in response.data] return _Wrapper(api_key, model, base_url)

í˜ì´ì§€ ì„¤ì •

st.set_page_config(page_title="ë¦¬í¬íŠ¸ ê¸°ë°˜ ì¢…ëª© ì¶”ì²œ ì±—ë´‡", layout="centered") st.title("ğŸ“Š ë¯¸ë˜ì—ì…‹ ë¦¬í¬íŠ¸ ê¸°ë°˜ ì¢…ëª© ì¶”ì²œ ì±—ë´‡")

ì‚¬ì´ë“œë°”ì—ì„œ API ì •ë³´ ì…ë ¥

api_key = st.sidebar.text_input("ğŸ” API í‚¤ ì…ë ¥", type="password") base_url = st.sidebar.text_input("ğŸŒ API Base URL", value="https://api.hyperclova.naver.com/v1")

if not api_key: st.warning("API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.") st.stop()

í™˜ê²½ë³€ìˆ˜ ì„¤ì •

os.environ["OPENAI_API_KEY"] = api_key os.environ["OPENAI_API_BASE"] = base_url

LLM ì´ˆê¸°í™”

llm = ChatOpenAI( model_name="hyperclova-x-large", temperature=0.7, openai_api_key=api_key, openai_api_base=base_url )

ì„ë² ë”© ì´ˆê¸°í™”

embeddings = HyperclovaEmbeddings(api_key=api_key, base_url=base_url)

DB ì´ˆê¸°í™” ë° í”¼ë“œë°± ì €ì¥ í•¨ìˆ˜

def init_db(): conn = sqlite3.connect("feedback.db") cur = conn.cursor() cur.execute(""" CREATE TABLE IF NOT EXISTS feedback ( id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT, investor_type TEXT, question TEXT, answer TEXT )""") conn.commit() conn.close()

def save_feedback(investor_type, question, answer): conn = sqlite3.connect("feedback.db") cur = conn.cursor() cur.execute(""" INSERT INTO feedback (timestamp, investor_type, question, answer) VALUES (?, ?, ?, ?) """, ( datetime.now().strftime("%Y-%m-%d %H:%M"), investor_type, question, answer )) conn.commit() conn.close()

ë³´ê³ ì„œ ë§í¬ ë° PDF ì¶”ì¶œ í•¨ìˆ˜

def fetch_report_links(limit=5): base = "https://securities.miraeasset.com" list_url = f"{base}/bbs/board/message/list.do?categoryId=1521" headers = {"User-Agent": "Mozilla/5.0"} resp = requests.get(list_url, headers=headers) soup = BeautifulSoup(resp.text, "html.parser") links = [] for a in soup.select("div.board_list a"): title = a.text.strip() href = a.get("href") if href and "view.do" in href: links.append((title, base + href)) if len(links) >= limit: break return links

def fetch_pdf_urls(report_links): base = "https://securities.miraeasset.com" headers = {"User-Agent": "Mozilla/5.0"} pdfs = [] for title, detail_url in report_links: resp = requests.get(detail_url, headers=headers) soup = BeautifulSoup(resp.text, "html.parser") a = soup.find("a", href=lambda x: x and x.endswith(".pdf")) if a: href = a["href"] pdfs.append((title, href if href.startswith("http") else base + href)) return pdfs

QA ì²´ì¸ êµ¬ì„± í•¨ìˆ˜

def build_qa_chain(): report_links = fetch_report_links() pdf_urls = fetch_pdf_urls(report_links) docs = [] for title, pdf_url in pdf_urls: try: resp = requests.get(pdf_url, headers={"User-Agent": "Mozilla/5.0"}) tmp_path = os.path.join(tempfile.gettempdir(), os.path.basename(pdf_url)) with open(tmp_path, "wb") as f: f.write(resp.content) loader = PyPDFLoader(tmp_path) docs.extend(loader.load_and_split()) except Exception as e: st.error(f"ë³´ê³ ì„œ '{title}' ë¡œë”© ì‹¤íŒ¨: {e}") splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100) texts = splitter.split_documents(docs) vectordb = FAISS.from_documents(texts, embeddings) qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever()) return qa

ë©”ì¸ ì‹¤í–‰ ë¡œì§

init_db() user_type = st.selectbox("íˆ¬ì ì„±í–¥ì„ ì„ íƒí•˜ì„¸ìš”", ["ì„±ì¥", "ë°°ë‹¹", "ê°€ì¹˜", "ë‹¨íƒ€"]) question = st.text_input("ê´€ì‹¬ ìˆëŠ” ì§ˆë¬¸ì´ë‚˜ ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš”")

if question: with st.spinner("ë¦¬í¬íŠ¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."): qa_chain = build_qa_chain() answer = qa_chain.run(question) st.success("ğŸ“Œ ì¶”ì²œ ê²°ê³¼") st.write(answer) save_feedback(user_type, question, answer) st.markdown("---") st.markdown("ğŸ§¾ ë¶„ì„ì— ì‚¬ìš©ëœ ë³´ê³ ì„œ ëª©ë¡ ë° ë§í¬:") for title, url in fetch_report_links(): st.markdown(f"- {title}")

